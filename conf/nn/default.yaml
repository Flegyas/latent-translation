data: ???

module:
  optimizer:
    _target_: torch.optim.Adam
    lr: 1e-3
    betas: [ 0.9, 0.999 ]
    eps: 1e-08
    weight_decay: 0

#  lr_scheduler:
#    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
#    T_0: 20
#    T_mult: 1
#    eta_min: 0
#    last_epoch: -1
#    verbose: False


defaults:
  - _self_
  - data: default
  - module: default
